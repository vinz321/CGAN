{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import functional as transformF\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import gc\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patchdisc import PatchDiscriminator\n",
    "from UNet import Unet\n",
    "from FlowGenV2 import FlowGen\n",
    "from datasets import DNSDatasetCustom, full_dns_dataset\n",
    "from Loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"C:\\\\Users\\\\vicin\\Desktop\\\\PoliTo\\\\ML_for_CV\\\\CGAN\"\n",
    "BATCH_SIZE=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNSDataset(Dataset):\n",
    "    def __init__(self, img_dir, seg=True, norm=True, depth=True, with_previous=False, transforms=None, target_transforms=None):\n",
    "        self.img_dir=img_dir\n",
    "        self.imgs_depth=[]\n",
    "        self.imgs_norm=[]\n",
    "        self.imgs_seg=[]\n",
    "        self.imgs_col=[]\n",
    "        self.norm=norm\n",
    "        self.seg=seg\n",
    "        self.depth=depth\n",
    "        self.with_previous=with_previous\n",
    "\n",
    "        if depth:\n",
    "            self.imgs_depth.extend([self.img_dir + '\\\\Depth\\\\'+i for i in os.listdir(self.img_dir+'\\\\Depth') if i.endswith('.png')])\n",
    "        if norm:\n",
    "            self.imgs_norm.extend([self.img_dir + '\\\\Normal\\\\'+i for i in os.listdir(self.img_dir+'\\\\Normal') if i.endswith('.png')])\n",
    "        if seg:\n",
    "            self.imgs_seg.extend([self.img_dir + '\\\\Segmentation\\\\'+i for i in os.listdir(self.img_dir+'\\\\Segmentation') if i.endswith('.png')])\n",
    "        \n",
    "        self.imgs_col.extend([self.img_dir + '\\\\Default\\\\'+i for i in os.listdir(self.img_dir+'\\\\Default') if i.endswith('.png')])\n",
    "        \n",
    "        self.transforms=transforms\n",
    "        self.target_transforms=target_transforms\n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        tensors=[]\n",
    "        if self.with_previous:\n",
    "            prev_frame=transformF.to_tensor(Image.open(self.imgs_col[0]))[0:3] #index invece che 0\n",
    "            tensors.append(prev_frame)\n",
    "            index=index+1\n",
    "\n",
    "        if self.depth:\n",
    "            depth=transformF.to_tensor(transformF.to_grayscale(Image.open(self.imgs_depth[index])))\n",
    "            tensors.append(depth)\n",
    "        if self.norm:\n",
    "            norm=transformF.to_tensor(Image.open(self.imgs_norm[index]))[0:3]\n",
    "            tensors.append(norm)\n",
    "        if self.seg:\n",
    "            seg=transformF.to_tensor(Image.open(self.imgs_seg[index]))[0:3]\n",
    "            tensors.append(seg)\n",
    "        col=transformF.to_tensor(Image.open(self.imgs_col[index]))[0:3]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return torch.cat(tensors,0), col\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.with_previous:\n",
    "            return len(self.imgs_col)-1\n",
    "        return len(self.imgs_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.45,0.432,0.411], std=[1,1,1])\n",
    "    ])\n",
    "\n",
    "co_transform = transforms.Compose([\n",
    "            \n",
    "            transforms.RandomRotation(10,interpolation=transforms.InterpolationMode.BILINEAR,expand=True),\n",
    "            transforms.RandomCrop((256,256)),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomHorizontalFlip()\n",
    "        ])\n",
    "\n",
    "dataset_train=DNSDatasetCustom(PATH+'\\\\dataset\\\\Cam 1', set_order='dc,ds')\n",
    "dataset_train_2=DNSDatasetCustom(PATH+'\\\\dataset\\\\Cam 2',  set_order='dc,ds')\n",
    "dataset_train_3=DNSDatasetCustom(PATH+'\\\\dataset\\\\Cam 3', set_order='dc,ds')\n",
    "dataset_train_4=DNSDatasetCustom(PATH+'\\\\dataset\\\\Cam 4', set_order='dc,ds')\n",
    "dataset_test=DNSDataset(PATH+'\\\\dataset\\\\Cam 4', norm=False, with_previous=True)\n",
    "\n",
    "dataset_train=ConcatDataset((dataset_train,dataset_train_2, dataset_train_3))\n",
    "\n",
    "dataset_train=full_dns_dataset(PATH+'\\\\dataset', 'Cam ',1,10, 'dc,dsn',transforms=input_transform, co_transform=co_transform)\n",
    "#dataset_train,_=random_split(dataset_train,[32,len(dataset_train)-32])\n",
    "dataloader_train=DataLoader(dataset_train,BATCH_SIZE, shuffle=True)\n",
    "dataloader_test=DataLoader(dataset_train_4,BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(img0_norm.permute(1,2,0))\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(img0_depth.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100, 2, 2])\n",
      "dict_keys(['state_dict', 'best_EPE', 'epoch', 'arch'])\n",
      "dict_keys(['Discriminator', 'optimizerDiscriminator_state_dict', 'Generator', 'optimizerUNet_state_dict', 'epoch'])\n",
      "[1, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "r=torch.randn(16,100,2,2).cuda()\n",
    "\n",
    "print(r.shape)\n",
    "\n",
    "flowgen=FlowGen(unet_pretrained='.\\\\models\\\\neverStreetsUnet.pth.tar').cuda()\n",
    "flowgen.reload_pretrained()\n",
    "flowgen.apply(weights_init)\n",
    "\n",
    "patch_discriminator=PatchDiscriminator(18,32).cuda()\n",
    "patch_discriminator.apply(weights_init)\n",
    "\n",
    "with torch.no_grad():\n",
    "    r=torch.randn(1,18,256,256).cuda()\n",
    "    patch_shape=list(patch_discriminator(r).shape[1:4])\n",
    "    print(patch_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizerDec=optim.Adam(decoder.parameters(), 0.0002, (0.5,0.999))\n",
    "\n",
    "# enc_dec_param=list(decoder.parameters())+list(encoder.parameters())\n",
    "# optimizerEncDec=optim.Adam(enc_dec_param, 0.0002, (0.5,0.999))\n",
    "\n",
    "optimizerPatchDiscriminator=optim.Adam(patch_discriminator.parameters(), .0002, (0.5,0.9))\n",
    "optimizerflowgen=optim.Adam(flowgen.parameters(),.0002, (0.5,0.9) )\n",
    "\n",
    "criterion=LossCustomDisc()\n",
    "criterion_flowgen=LossCustom()\n",
    "\n",
    "# criterion=nn.BCELoss()\n",
    "criterion_encoder=nn.SmoothL1Loss()\n",
    "\n",
    "loss_iterations=0\n",
    "loss_gen_values=[]\n",
    "loss_gen_pix_values=[]\n",
    "loss_disc_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-Loop GAN ###\n",
    "def optimize_GAN():\n",
    "    global dataloader_train, loss_iterations,loss_gen_values,loss_disc_values, loss_gen_pix_values\n",
    "    accuracy=0\n",
    "    for (data,col) in dataloader_train:\n",
    "\n",
    "        batch_size=len(data)\n",
    "        data_gpu=data.cuda()\n",
    "        col_gpu=col.cuda()\n",
    "\n",
    "        fake_col=flowgen(data_gpu)\n",
    "\n",
    "        ### Train Discriminator ### \n",
    "        patch_discriminator.zero_grad()\n",
    "        flowgen.zero_grad()\n",
    "        \n",
    "        label1=torch.full([batch_size,*patch_shape], 1.).cuda() #Etichetta immagini reali\n",
    "\n",
    "        output1=patch_discriminator(torch.cat((data_gpu,col_gpu,),1)) # predizioni\n",
    "        loss_discr_real=criterion(output1, label1) # cross entropy\n",
    "\n",
    "\n",
    "        accuracy+=output1.round().eq(1.).sum().item()/64\n",
    "\n",
    "        label2=torch.full([batch_size,*patch_shape], 0.).cuda()\n",
    "\n",
    "\n",
    "        output2=patch_discriminator(torch.cat((data_gpu,fake_col.detach(),), 1) )\n",
    "        loss_discr_fake=criterion(output2,label2)\n",
    "\n",
    "        accuracy+=output2.round().eq(0.).sum().item()/64\n",
    "\n",
    "        \n",
    "        loss_discr=loss_discr_real+loss_discr_fake\n",
    "\n",
    "        loss_disc_values.append(torch.Tensor(loss_discr).item())\n",
    "        loss_discr.backward()\n",
    "        optimizerPatchDiscriminator.step()\n",
    "        \n",
    "        ### Train Generator ###\n",
    "        \n",
    "        output3=patch_discriminator(torch.cat((data_gpu,fake_col,),1))\n",
    "\n",
    "        loss_gen_disc=criterion(output3, label1)\n",
    "        loss_gen_pixel=criterion_flowgen(fake_col, col_gpu)\n",
    "        errDec = loss_gen_disc + loss_gen_pixel\n",
    "\n",
    "        loss_gen_pix_values.append(loss_gen_pixel.item())\n",
    "        loss_gen_values.append(loss_gen_disc.item())\n",
    "        \n",
    "        errDec.backward()\n",
    "        optimizerflowgen.step()\n",
    "\n",
    "        loss_iterations+=1\n",
    "\n",
    "        label1.cpu()\n",
    "        label2.cpu()\n",
    "        fake_col.cpu()\n",
    "        data_gpu.cpu()\n",
    "        col_gpu.cpu()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        #data_gpu[0].split(1,2)[0].squeeze()\n",
    "    return accuracy/len(dataloader_train.dataset), fake_col[0].squeeze(), col[0].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```def optimize_encoder_decoder():\n",
    "    global encoder, decoder, discriminator, dataloader_train\n",
    "    accuracy=0\n",
    "    for (data,seg) in dataloader_train:\n",
    "        batch_size=data.shape[0]\n",
    "        data_gpu=data.cuda()\n",
    "        seg_gpu=seg.cuda()\n",
    "\n",
    "        latent_batch=encoder(seg_gpu)\n",
    "\n",
    "        fake_data=decoder(latent_batch)\n",
    "\n",
    "        ### Train Discriminator ### \n",
    "        discriminator.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "\n",
    "        label1=torch.full((batch_size,), 1.).cuda() #Etichetta immagini reali\n",
    "        output1=discriminator(torch.cat([data_gpu,seg_gpu], dim=1)).view(-1) # predizioni\n",
    "        errDisc_real=criterion(output1, label1) # cross entropy\n",
    "\n",
    "        accuracy+=output1.eq(1.).sum().item()\n",
    "\n",
    "        label2=torch.full((batch_size,), 0.).cuda()\n",
    "        output2=discriminator(torch.cat([fake_data.detach(),seg_gpu], dim=1)).view(-1)\n",
    "        errDisc_fake=criterion(output2,label2)\n",
    "\n",
    "        accuracy+=output1.eq(0.).sum().item()\n",
    "\n",
    "        \n",
    "        errDisc=errDisc_real+errDisc_fake\n",
    "        errDisc.backward()\n",
    "        optimizerDisc.step()\n",
    "        \n",
    "        ### Train Decoder ###\n",
    "        \n",
    "        \n",
    "        # errDec=criterion_encoder(fake_data, data_gpu)\n",
    "\n",
    "        # errDec.backward()\n",
    "        # optimizerEncDec.step()\n",
    "\n",
    "        output3=discriminator(torch.cat([fake_data, seg_gpu], dim=1)).view(-1)\n",
    "        errGen=criterion(output3, label1)\n",
    "        errGen.backward()\n",
    "        optimizerEncDec.step()\n",
    "        fake_data.cpu()\n",
    "        data_gpu.cpu()\n",
    "        seg_gpu.cpu()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return accuracy/len(dataloader_train.dataset), fake_data[0], seg[0]```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "dict_keys(['state_dict', 'best_EPE', 'epoch', 'arch'])\n",
      "dict_keys(['Discriminator', 'optimizerDiscriminator_state_dict', 'Generator', 'optimizerUNet_state_dict', 'epoch'])\n",
      "Epoch  6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "### Train Loop ###\n",
    "epochs=1500\n",
    "start_epoch=0\n",
    "if \"neverStreets.pth.tar\" in os.listdir(\"./\"):\n",
    "  print(\"Loading...\")\n",
    "  try:\n",
    "    state = torch.load(\"./neverStreets.pth.tar\")\n",
    "    if state:\n",
    "      patch_discriminator.load_state_dict(state[\"Discriminator\"])\n",
    "      flowgen.load_state_dict(state[\"Generator\"])\n",
    "      optimizerPatchDiscriminator.load_state_dict(state[\"optimizerDiscriminator_state_dict\"])\n",
    "      optimizerflowgen.load_state_dict(state[\"optimizerFGen_state_dict\"])\n",
    "      start_epoch=state[\"epoch\"]\n",
    "\n",
    "\n",
    "\n",
    "  except:\n",
    "    print(\"Error in load\")\n",
    "\n",
    "  with open('loss_data.json', 'r') as f:\n",
    "    content=f.read()\n",
    "    content=json.loads(content)\n",
    "    loss_iterations=content['loss_iterations']\n",
    "    loss_gen_values=json.loads(content['loss_gen_values'])\n",
    "    loss_gen_pix_values=json.loads(content['loss_gen_pix_values'])\n",
    "    loss_disc_values=json.loads(content['loss_disc_values'])\n",
    "\n",
    "# flowgen.reload_flownet()\n",
    "flowgen.reload_pretrained()\n",
    "\n",
    "\n",
    "for i in range(start_epoch, epochs):\n",
    "  print(\"Epoch \",i)\n",
    "  accuracy, fake_col, col=optimize_GAN()\n",
    "  \n",
    "  clear_output(wait=True)\n",
    "  print(\"Saving...\")\n",
    "  torch.save({\"Discriminator\":patch_discriminator.state_dict(),\n",
    "  \"optimizerDiscriminator_state_dict\":optimizerPatchDiscriminator.state_dict(),\n",
    "  \"Generator\":flowgen.state_dict(),\n",
    "  \"optimizerFGen_state_dict\":optimizerflowgen.state_dict(),\n",
    "  \"epoch\":i},\n",
    "  \"./neverStreets.pth.tar\")\n",
    "\n",
    "  content={\n",
    "      'loss_iterations' : loss_iterations,\n",
    "      'loss_gen_values' : json.dumps(loss_gen_values),\n",
    "      'loss_gen_pix_values' : json.dumps(loss_gen_pix_values),\n",
    "      'loss_disc_values' : json.dumps(loss_disc_values)\n",
    "  }\n",
    "\n",
    "  with open('loss_data.json','w') as f:\n",
    "      f.write(json.dumps(content))\n",
    "\n",
    "  print(accuracy)\n",
    "  \n",
    "  plt.subplot(321)\n",
    "  plt.imshow(fake_col.cpu().detach().permute([1,2,0]))\n",
    "  plt.subplot(322)\n",
    "  plt.imshow(col.cpu().detach().permute([1,2,0]))\n",
    "  plt.subplot(323)\n",
    "  plt.plot(range(0,loss_iterations), loss_gen_values, 'g')\n",
    "  plt.subplot(324)\n",
    "  plt.plot(range(0,loss_iterations), loss_disc_values, 'r')\n",
    "  plt.subplot(325)\n",
    "  plt.plot(range(0,loss_iterations), loss_gen_pix_values, 'b')\n",
    "  plt.subplot(326)\n",
    "  plt.plot(range(0,loss_iterations), loss_gen_values, 'g')\n",
    "  plt.plot(range(0,loss_iterations), loss_disc_values, 'r')\n",
    "  plt.plot(range(0,loss_iterations), loss_gen_pix_values, 'b')\n",
    "  plt.savefig('plot.png')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save losses ###\n",
    "import json\n",
    "\n",
    "content={\n",
    "    'loss_iterations' : loss_iterations,\n",
    "    'loss_gen_values' : json.dumps(loss_gen_values),\n",
    "    'loss_gen_pix_values' : json.dumps(loss_gen_pix_values),\n",
    "    'loss_disc_values' : json.dumps(loss_disc_values)\n",
    "}\n",
    "\n",
    "with open('loss_data.json','w') as f:\n",
    "    f.write(json.dumps(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to create process using '\"C:\\Users\\vicin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe\" -m ipykernel_launcher --f=c:\\Users\\vicin\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-17796F6GsNDwRaokG.json'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random\n",
    "generator=FlowGen().cuda()\n",
    "\n",
    "if \"neverStreets\" in os.listdir(\"./\"):\n",
    "  print(\"Loading...\")\n",
    "  try:\n",
    "    state = torch.load(\"./neverStreets\")\n",
    "    if state:\n",
    "      generator.load_state_dict(state[\"Generator\"])\n",
    "  except:\n",
    "    print(\"Error in load\")\n",
    "\n",
    "\n",
    "print(len(dataloader_test))\n",
    "data,col=next(iter(dataloader_test))\n",
    "#fake_data=decoder(torch.randn([16,100,1,1], device='cuda'))\n",
    "r=random.randint(0, len(data)-1)\n",
    "fake_col=generator(data.cuda())\n",
    "\n",
    "to_image=transforms.ToPILImage()\n",
    "plt.subplot(121)\n",
    "plt.imshow(to_image(fake_col[r].clip(0,1).cpu()))\n",
    "plt.subplot(122)\n",
    "plt.imshow(to_image(col[r].squeeze().clip(0,1).cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML for CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
